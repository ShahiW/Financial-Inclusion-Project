{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "%run '5_FeatureEngineering.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set: 0.74\n",
      "Accuracy on test set: 0.72\n",
      "--------------------------------------------------------------------------------\n",
      "Mean absolute error on train set: 0.26\n",
      "Mean absolute error on test set: 0.28\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "import imblearn\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "# Logistic Regression (base?) - line model:\n",
    "df = pd.read_csv('data/data.csv')\n",
    "# create a new data frame without the NaN in our target feature\n",
    "df_wo_target_nan = df.dropna(axis=0)\n",
    "\n",
    "# Defining X and y\n",
    "features = df_wo_target_nan.columns.tolist()\n",
    "features.remove('bank_account')\n",
    "\n",
    "X = df_wo_target_nan[features]\n",
    "y = df_wo_target_nan.bank_account\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, shuffle=True)\n",
    "\n",
    "#Oversampling\n",
    "oversample = imblearn.over_sampling.RandomOverSampler(sampling_strategy='minority')\n",
    "X_train_over, y_train_over = oversample.fit_resample(X_train, y_train)\n",
    "\n",
    "# Encode categorical features\n",
    "enc = preprocessing.OrdinalEncoder()\n",
    "X_train_fitted_transformed = enc.fit_transform(X_train_over)\n",
    "X_test_fitted_transformed = enc.fit_transform(X_test)\n",
    "\n",
    "\n",
    "### Using Logistic regression using non-scaled data\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=10000)\n",
    "log_reg.fit(X_train_fitted_transformed, y_train_over)\n",
    "\n",
    "y_pred_train = log_reg.predict(X_train_fitted_transformed)\n",
    "y_pred = log_reg.predict(X_test_fitted_transformed)\n",
    "\n",
    "# Print accuracy of our model\n",
    "print(\"Accuracy on train set:\", round(accuracy_score(y_train_over, y_pred_train), 2))\n",
    "print(\"Accuracy on test set:\", round(accuracy_score(y_test, y_pred), 2))\n",
    "print(\"--------\"*10)\n",
    "# Print MAE of our model\n",
    "y_pred_train_ = []\n",
    "y_pred_ = []\n",
    "for i in y_pred_train:\n",
    "    if i == 'Yes': y_pred_train_.append(1)\n",
    "    if i == 'No': y_pred_train_.append(0)\n",
    "for i in y_pred:\n",
    "    if i == 'Yes': y_pred_.append(1)\n",
    "    if i == 'No': y_pred_.append(0) \n",
    "print(\"Mean absolute error on train set:\", round(mean_absolute_error(y_train_over.replace (('Yes','No'), (1,0)), y_pred_train_),2))\n",
    "print(\"Mean absolute error on test set:\", round(mean_absolute_error(y_test.replace (('Yes','No'), (1,0)), y_pred_),2))\n",
    "print(\"--------\"*10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# #y_train_over.replace (('Yes','No'), (1,0))\n",
    "# y_pred_train_ = []\n",
    "# for i in y_pred_train:\n",
    "#     if i == 'Yes': y_pred_train_.append(1)\n",
    "#     if i == 'No': y_pred_train_.append(0)\n",
    "\n",
    "print (type(y_test))\n",
    "print (type(y_train_over))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# erst train - test - split, dann remove imbalance of data;\n",
    "\n",
    "# Defining X and y\n",
    "features = df_cleaned.columns.tolist()\n",
    "features.remove('bank_account_Yes')\n",
    "\n",
    "X = df_cleaned[features]\n",
    "y = df_cleaned.bank_account_Yes\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, shuffle=True)\n",
    "\n",
    "# Check the shape of the data sets\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"X_test:\", X_test.shape)\n",
    "print(\"y_test:\", y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce imbalance of data\n",
    "\n",
    "1. Random Oversampling: Randomly duplicate examples in the minority class.\n",
    "2. Random Undersampling: Randomly delete examples in the majority class.\n",
    "\n",
    "class imblearn.over_sampling.RandomOverSampler(*, sampling_strategy='auto', random_state=None, shrinkage=None)[source]\n",
    "\n",
    "Class to perform random over-sampling."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import accuracy_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Oversampling\n",
    "oversample = imblearn.over_sampling.RandomOverSampler(sampling_strategy='minority')\n",
    "X_train_over, y_train_over = oversample.fit_resample(X_train, y_train)\n",
    "\n",
    "display('X_train: ' + str(X_train.shape))\n",
    "display('y_train: ' + str(y_train.shape))\n",
    "display('X_train_over: ' + str(X_train_over.shape))\n",
    "display('y_train_over: ' + str(y_train_over.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_yes, count_no = 0, 0\n",
    "\n",
    "for i in y_train_over:\n",
    "    if i == True: \n",
    "        count_yes += 1\n",
    "    if i == False: \n",
    "        count_no += 1\n",
    "print (count_yes, count_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Undersampling\n",
    "undersample = imblearn.under_sampling.RandomUnderSampler(sampling_strategy='majority')\n",
    "X_train_under, y_train_under = undersample.fit_resample(X_train, y_train)\n",
    "\n",
    "count_yes, count_no = 0, 0\n",
    "\n",
    "for i in y_train_under:\n",
    "    if i == True: \n",
    "        count_yes += 1\n",
    "    if i == False: \n",
    "        count_no += 1\n",
    "print (count_yes, count_no)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictive Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Using Logistic regression using non-scaled data\n",
    "\n",
    "# Logistic Regression without the id field\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train_over, y_train_over)\n",
    "\n",
    "y_pred_train = log_reg.predict(X_train_over)\n",
    "y_pred = log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print accuracy of our model\n",
    "print(\"Accuracy on train set:\", round(accuracy_score(y_train_over, y_pred_train), 2))\n",
    "print(\"Accuracy on test set:\", round(accuracy_score(y_test, y_pred), 2))\n",
    "print(\"--------\"*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation (see description)\n",
    "\n",
    "The evaluation metric for this challenge is Mean Absolute error, where 1 indicates that the individual does have a bank account and 0 indicates that they do not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print accuracy of our model\n",
    "print(\"Accuracy on train set:\", round(accuracy_score(y_train_over, y_pred_train), 2))\n",
    "print(\"Accuracy on test set:\", round(accuracy_score(y_test, y_pred), 2))\n",
    "print(\"--------\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print MAE of our model\n",
    "print(\"Mean absolute error on train set:\", round(mean_absolute_error(pd.DataFrame(map(int, y_train_over)), pd.DataFrame(map(int, y_pred_train))),2))\n",
    "print(\"Mean absolute error on test set:\", round(mean_absolute_error(pd.DataFrame(map(int, y_test)), pd.DataFrame(map(int, y_pred))),2))\n",
    "print(\"--------\"*10)\n",
    "\n",
    "# Result: Model seems overfittet, da im Test-Data-Set mehr Fehler auftreten als im Trainingsdataset.\n",
    "# Mean absolute error bedeutet: in wie vielen Fällen lag die Vorhersage Falsch?\n",
    "# MAE = 1 - Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (pd.DataFrame(map(int, y_train_over)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show confusion matrix based on predicted results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm_train = confusion_matrix(y_train_over, y_pred_train)\n",
    "sns.heatmap(cm_train, cmap=\"YlGnBu\", annot=True, fmt='d');\n",
    "\n",
    "\n",
    "# Das ist für das Train - Datenset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_test = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm_test, cmap=\"YlGnBu\", annot=True, fmt='d');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improve Accuracy/MAE with Logistic Regression with Randomsearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from scipy.stats import loguniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "log_reg_with_randomS= LogisticRegression(max_iter=10)\n",
    "\n",
    "# define evaluation\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "\n",
    "# define search space\n",
    "param_grid = { \"solver\" : ['newton-cg', 'lbfgs', 'liblinear'],      # Hier werden die Hyperparameter definiert, die untersucht\n",
    "               \"penalty\" : ['none', 'l1', 'l2', 'elasticnet']}      # werden sollen\n",
    "\n",
    "\n",
    "# define Random search\n",
    "Random_search = RandomizedSearchCV(log_reg_with_randomS, param_grid, n_iter=500, scoring='accuracy', n_jobs=1, cv=cv, random_state=1)\n",
    "\n",
    "# execute Random search\n",
    "Random_search.fit(X_train_under, y_train_under)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train_RS = Random_search.predict(X_train_under)\n",
    "y_pred_RS = Random_search.predict(X_test)\n",
    "\n",
    "print(\"Tuned hpyerparameters :(best parameters) \",Random_search.best_params_)\n",
    "print(\"Accuracy on test set:\", round(accuracy_score(y_test, y_pred_RS), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.logspace(0, 4, num=10)\n",
    "penalty = ['l1', 'l2']\n",
    "solver = ['liblinear', 'saga']\n",
    "\n",
    "hyperparameters = dict(penalty=penalty, solver=solver)\n",
    "\n",
    "gridsearch = GridSearchCV(log_reg, hyperparameters, scoring='accuracy',\n",
    "                  cv=5, verbose=5, n_jobs=1)\n",
    "gridsearch.fit(X_train_under,y_train_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train_GS = gridsearch.predict(X_train_under)\n",
    "y_pred_GS = gridsearch.predict(X_test)\n",
    "\n",
    "print(\"Tuned hpyerparameters (best parameters): \",gridsearch.best_params_)\n",
    "print(\"Accuracy on test set:\", round(accuracy_score(y_test, y_pred_GS), 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
