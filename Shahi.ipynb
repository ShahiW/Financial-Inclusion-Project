{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data into a dataframe\n",
    "test_original = pd.read_csv('data/Test.csv')\n",
    "train_original = pd.read_csv('data/train.csv')\n",
    "\n",
    "#test = test.drop('uniqueid', axis=1)\n",
    "#train = train.drop('uniqueid', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make bins for household size in train\n",
    "household_bins = pd.cut(train_original['household_size'], [1, 3, 7, 10, 25], labels=['single', 'small', 'average', 'big'])\n",
    "household_bins.name = 'household_sizes'\n",
    "\n",
    "train = train_original.join(household_bins, how='inner')\n",
    "train = train.drop('household_size', axis=1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make bins for household size in test\n",
    "household_bins = pd.cut(test_original['household_size'], [1, 3, 7, 10, 25], labels=['single', 'small', 'average', 'big'])\n",
    "household_bins.name = 'household_sizes'\n",
    "\n",
    "test = test_original.join(household_bins, how='inner')\n",
    "test = test.drop('household_size', axis=1)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make bins for age in train\n",
    "age_bins = pd.cut(train_original['age_of_respondent'], [0, 16, 45, 75, 100], labels=['child', 'adult', 'elder', 'old'])\n",
    "age_bins.name = 'ages'\n",
    "\n",
    "train = train_original.join(age_bins, how='inner')\n",
    "train = train.drop('age_of_respondent', axis=1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make bins for age in test\n",
    "age_bins = pd.cut(test_original['age_of_respondent'], [0, 16, 45, 75, 100], labels=['child', 'adult', 'elder', 'old'])\n",
    "age_bins.name = 'ages'\n",
    "\n",
    "test = test_original.join(age_bins, how='inner')\n",
    "test = test.drop('age_of_respondent', axis=1)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unique id for train and test df\n",
    "test = test.drop('uniqueid', axis=1)\n",
    "train = train.drop('uniqueid', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dummie variables for train\n",
    "train = pd.get_dummies(train, drop_first=True)\n",
    "train.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dummie variables for test\n",
    "test = pd.get_dummies(test, drop_first=True)\n",
    "test.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test Split\n",
    "\n",
    "# Defining X and y\n",
    "features = train.columns.tolist()\n",
    "features.remove('bank_account_Yes')\n",
    "\n",
    "X = train[features]\n",
    "y = train.bank_account_Yes\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, shuffle=True, stratify=y)\n",
    "\n",
    "# Check the shape of the data sets\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"X_test:\", X_test.shape)\n",
    "print(\"y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform undersampling on the majority class\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_train_under, y_train_under = undersampler.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform oversampling on the minority class\n",
    "oversampler = SMOTE(random_state=42)\n",
    "X_train_over, y_train_over = oversampler.fit_resample(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree\n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "y_pred_tree = dtree.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred_tree))\n",
    "print(classification_report(y_test, y_pred_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree with undersampling\n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_train_under, y_train_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with undersampling\n",
    "y_pred_tree = dtree.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred_tree))\n",
    "print(classification_report(y_test, y_pred_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree with oversampling\n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_train_over, y_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with oversampling\n",
    "y_pred_tree = dtree.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred_tree))\n",
    "print(classification_report(y_test, y_pred_tree))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Random Forest\n",
    "forest = RandomForestClassifier()\n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "y_pred_forest = dtree.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred_forest))\n",
    "print(classification_report(y_test, y_pred_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Random Forest with undersampling\n",
    "forest = RandomForestClassifier()\n",
    "forest.fit(X_train_under, y_train_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict with undersampling\n",
    "y_pred_forest = dtree.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred_forest))\n",
    "print(classification_report(y_test, y_pred_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Random Forest with oversampling\n",
    "forest = RandomForestClassifier()\n",
    "forest.fit(X_train_over, y_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with oversampling\n",
    "y_pred_forest = dtree.predict(X_test)\n",
    "print(y_pred_forest)\n",
    "print(confusion_matrix(y_test, y_pred_forest))\n",
    "print(classification_report(y_test, y_pred_forest))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree w/o over- or undersampling has best precision\n",
    "__Fit test data to model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining X and  for test\n",
    "features = test.columns.tolist()\n",
    "X = test[features]\n",
    "\n",
    "# Predict\n",
    "y_pred_tree = dtree.predict(X)\n",
    "# print(type(y_pred_tree))\n",
    "series = pd.Series(y_pred_tree).astype(int)\n",
    "series.name = 'bank_account'\n",
    "\n",
    "test_new = pd.concat([test, series], axis=1).astype(bool)\n",
    "test_new.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make countplot for bank_account of train dataset\n",
    "# Countplot with bank account, hue=gender\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "sns.countplot(x=train['bank_account_Yes'], hue=train['gender_of_respondent_Male']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make countplot for bank_account of test dataset\n",
    "# Countplot with bank account, hue=gender\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "sns.countplot(x=test_new['bank_account'], hue=test_new['gender_of_respondent_Male']);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the KNN Model with the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting features and target\n",
    "X = train.drop('bank_account_Yes', axis=1)\n",
    "y = train['bank_account_Yes']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the k-NN model\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "knn.fit(X_train, y_train)  \n",
    "\n",
    "# Make predictions\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Calculate and print the classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining X and  for test\n",
    "features = test.columns.tolist()\n",
    "X = test[features]\n",
    "\n",
    "# Predict\n",
    "y_pred_final = knn.predict(X)\n",
    "# print(type(y_pred_tree))\n",
    "series_knn = pd.Series(y_pred_final).astype(int)\n",
    "series_knn = series_knn.astype(bool)\n",
    "series_knn.name = 'bank_account'\n",
    "\n",
    "#test_new = pd.concat([test, series], axis=1).astype(bool)\n",
    "#test_new.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_original = pd.concat([test_original, series_knn], axis=1)\n",
    "#test_original.head()\n",
    "test_original.info()\n",
    "#test_original.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge train and test_new on unique id:\n",
    "final_df = train_original.merge(test_original, how='outer') \n",
    "final_df.info()\n",
    "final_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if value a boolean\n",
    "def bool2yes(boolean):\n",
    "    if isinstance(boolean, bool):\n",
    "        if boolean == True:\n",
    "            return \"Yes\"\n",
    "        else:\n",
    "            return \"No\"\n",
    "    else:\n",
    "        return boolean\n",
    "    \n",
    "final_df.applymap(bool2yes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the dataframe into a csv:\n",
    "'''\n",
    "# Define the path to the folder in your repository\n",
    "folder_path = 'data/'\n",
    "\n",
    "# Define the file name and extension\n",
    "file_name = 'final_df.csv'\n",
    "\n",
    "# Concatenate the folder path and file name\n",
    "file_path = f'{folder_path}/{file_name}'\n",
    "\n",
    "# Export the DataFrame to the specified folder\n",
    "final_df.to_csv(file_path, index=False)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
